{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXt4xMlA+stITDlfhy1ijb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvanarvind/sleep-analysis/blob/main/Sleep_Analysis_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sleep Analysis - Final Project\n",
        "\n",
        "### -Yuvan"
      ],
      "metadata": {
        "id": "42ff30H1D5ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aUxisuTL9a8N",
        "outputId": "a89219d5-27ae-4dd9-f275-152631109d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn shap matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "pd.options.display.max_columns = 200\n"
      ],
      "metadata": {
        "id": "fQn2A4eI-d88"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTKr_svz-f6u",
        "outputId": "3af68291-f9e8-440d-ec8b-7ab5e6eb3062"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset from Drive"
      ],
      "metadata": {
        "id": "XTT4tSoEEHa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/XAI\"\n",
        "RING_DATA_DIR = os.path.join(DRIVE_BASE, \"ring_data\")\n",
        "OUTPUT_DIR = os.path.join(DRIVE_BASE, \"sleep_xai_outputs\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Get all CSV files inside ring_data folder\n",
        "csv_files = glob.glob(os.path.join(RING_DATA_DIR, \"*.csv\"))\n",
        "\n",
        "print(\"Found files:\", len(csv_files))\n",
        "csv_files[:5]    # show first 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dQ0KUPMDqSw",
        "outputId": "6db917c7-55db-4709-f6be-fd144cc645d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: 70\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/XAI/ring_data/ring_data_2025_15.csv',\n",
              " '/content/drive/MyDrive/XAI/ring_data/ring_data_2025_38.csv',\n",
              " '/content/drive/MyDrive/XAI/ring_data/ring_data_2025_3.csv',\n",
              " '/content/drive/MyDrive/XAI/ring_data/ring_data_2025_39.csv',\n",
              " '/content/drive/MyDrive/XAI/ring_data/ring_data_2025_35.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and combine all CSVs\n"
      ],
      "metadata": {
        "id": "Bm-DXtqFpjef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_list = []\n",
        "\n",
        "for file in csv_files:\n",
        "    temp_df = pd.read_csv(file)\n",
        "    df_list.append(temp_df)\n",
        "\n",
        "df_all = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(df_all.shape)\n",
        "df_all.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "RXZemLcgphti",
        "outputId": "a51d605a-1074-4281-c526-d657194144f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3941686730.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and combine all CSVs from ring_data directory\n",
        "df_list = []\n",
        "for file in csv_files:\n",
        "    df_list.append(pd.read_csv(file))\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)   # <-- rename combined dataset to df\n"
      ],
      "metadata": {
        "id": "lbfZT2ntqSEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe(include='all')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "e8tz3khUD3lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pivot from long → wide format"
      ],
      "metadata": {
        "id": "sDxv6Y3S3JC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot long → wide\n",
        "df_wide = df.pivot(index=\"timestamp_epoch\", columns=\"data_type\", values=\"value\").reset_index()\n",
        "\n",
        "# Convert epoch to datetime\n",
        "df_wide[\"timestamp\"] = pd.to_datetime(df_wide[\"timestamp_epoch\"], unit=\"s\")\n",
        "\n",
        "# Sort\n",
        "df_wide = df_wide.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "df_wide.head()\n"
      ],
      "metadata": {
        "id": "tRRBJk1u2nMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort & Resample to 1-minute intervals"
      ],
      "metadata": {
        "id": "YXhduBHi3IIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot long → wide\n",
        "df_wide = df.pivot(index=\"timestamp_epoch\", columns=\"data_type\", values=\"value\").reset_index()\n",
        "\n",
        "# Convert epoch to datetime\n",
        "df_wide[\"timestamp\"] = pd.to_datetime(df_wide[\"timestamp_epoch\"], unit=\"s\")\n",
        "\n",
        "# Sort\n",
        "df_wide = df_wide.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "df_wide.head()\n",
        "\n",
        "# Use timestamp as index\n",
        "df_wide = df_wide.set_index(\"timestamp\")\n",
        "\n",
        "# Resample to 1-minute intervals (fill missing values with forward-fill)\n",
        "df_resampled = df_wide.resample(\"1T\").mean().ffill().bfill()\n",
        "\n",
        "df_resampled.head()\n"
      ],
      "metadata": {
        "id": "kzhkenrFBp-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rolling features (5-minute window)\n",
        "df_resampled[\"hr_rolling\"]   = df_resampled[\"raw_hr\"].rolling(5).mean()\n",
        "df_resampled[\"hrv_rolling\"]  = df_resampled[\"raw_hrv_2\"].rolling(5).mean()\n",
        "df_resampled[\"motion_roll\"]  = df_resampled[\"raw_motion\"].rolling(5).mean()\n",
        "df_resampled[\"temp_roll\"]    = df_resampled[\"temp\"].rolling(5).mean()\n",
        "df_resampled[\"rr_roll\"]      = df_resampled[\"respiratory_rate\"].rolling(5).mean()\n"
      ],
      "metadata": {
        "id": "gEN6B_mR3NfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled[\"stillness_index\"] = 1 / (1 + df_resampled[\"raw_motion\"])\n"
      ],
      "metadata": {
        "id": "iLLDdAHg3h4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled[\"slowing_score\"] = (\n",
        "    (df_resampled[\"hr_rolling\"].max() - df_resampled[\"hr_rolling\"]) +\n",
        "    (df_resampled[\"hrv_rolling\"] - df_resampled[\"hrv_rolling\"].min())\n",
        ")\n"
      ],
      "metadata": {
        "id": "EfR_RHqG3jF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled[\"awake_flag\"] = (df_resampled[\"steps\"] > 0).astype(int)\n"
      ],
      "metadata": {
        "id": "9OOjCkEh3k1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.tail()\n"
      ],
      "metadata": {
        "id": "PHAWm60l3mjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sleep Score Formula\n",
        "Normalize features (Z-score)"
      ],
      "metadata": {
        "id": "2PYTHUyC4oPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "features_to_scale = [\n",
        "    \"hr_rolling\", \"hrv_rolling\", \"motion_roll\",\n",
        "    \"rr_roll\", \"temp_roll\"\n",
        "]\n",
        "\n",
        "df_scaled = df_resampled.copy()\n",
        "df_scaled[features_to_scale] = scaler.fit_transform(df_scaled[features_to_scale])\n"
      ],
      "metadata": {
        "id": "5zhHsRfh4txl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a weighted sleep score"
      ],
      "metadata": {
        "id": "13A0xMxY6Mla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled[\"sleep_score_raw\"] = (\n",
        "    (-df_scaled[\"hr_rolling\"] * 0.20) +\n",
        "    ( df_scaled[\"hrv_rolling\"] * 0.25) +\n",
        "    (-df_scaled[\"motion_roll\"] * 0.25) +\n",
        "    (-df_scaled[\"rr_roll\"] * 0.15) +\n",
        "    (-df_scaled[\"temp_roll\"] * 0.15)\n",
        ")\n"
      ],
      "metadata": {
        "id": "vrhydrph4w5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to a clean 0–100 scale"
      ],
      "metadata": {
        "id": "L5XcC8Au6NPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-max scale to 0–100\n",
        "score_min = df_scaled[\"sleep_score_raw\"].min()\n",
        "score_max = df_scaled[\"sleep_score_raw\"].max()\n",
        "\n",
        "df_scaled[\"sleep_score\"] = (\n",
        "    (df_scaled[\"sleep_score_raw\"] - score_min) /\n",
        "    (score_max - score_min)\n",
        ") * 100\n"
      ],
      "metadata": {
        "id": "2mrgZRtC4zMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check sleep_score"
      ],
      "metadata": {
        "id": "_0IFSOTn6PNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled[[\"sleep_score\"]].describe()\n"
      ],
      "metadata": {
        "id": "j3BUe0Le424I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select Features & Prepare Train/Test Data"
      ],
      "metadata": {
        "id": "aCrxpS1y6RVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select features and target\n",
        "feature_cols = [\"hr_rolling\", \"hrv_rolling\", \"motion_roll\", \"rr_roll\", \"temp_roll\"]\n",
        "target_col = \"sleep_score\"\n",
        "\n",
        "X = df_scaled[feature_cols]\n",
        "y = df_scaled[target_col]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X.shape, y.shape\n"
      ],
      "metadata": {
        "id": "jgjvhK-L6TCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Simple, Interpretable Model"
      ],
      "metadata": {
        "id": "9gxMYssh7y-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a Random Forest model\n",
        "# Drop rows where sleep_score is NaN\n",
        "df_model = df_scaled.dropna(subset=[\"sleep_score\"])\n",
        "\n",
        "# Then drop/fill remaining NaNs in features\n",
        "df_model = df_model.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "\n",
        "# Redefine X and y cleanly\n",
        "X = df_model[feature_cols]\n",
        "y = df_model[target_col]\n",
        "\n",
        "# Train/test split again\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X.shape, y.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "wk4bkgtV73OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a Random Forest model\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Sleep Model trained!\")\n"
      ],
      "metadata": {
        "id": "XQZtr0MX8RJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model (RMSE + R²)"
      ],
      "metadata": {
        "id": "C6sz7SPJ8Zws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# RMSE (manual)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# R2\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"R²:   {r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "xTxKoEfl8a67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate SHAP values"
      ],
      "metadata": {
        "id": "E9kplySm8_ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize SHAP explainer\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# Compute SHAP values for the test set\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"SHAP values computed!\")\n"
      ],
      "metadata": {
        "id": "5LddliPY8_Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP Summary Plot"
      ],
      "metadata": {
        "id": "nAa56wHE9Ig6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "gSRg08y99KJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert SHAP values into confidence percentages\n"
      ],
      "metadata": {
        "id": "Ao7wARUk9nKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_names = X_test.columns.tolist()\n",
        "shap_abs = np.abs(shap_single)\n",
        "\n",
        "# Normalize to percentages\n",
        "confidence_scores = shap_abs / shap_abs.sum() * 100\n",
        "\n",
        "# Create a readable table\n",
        "explanation_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"shap_value\": shap_single,\n",
        "    \"confidence_percent\": confidence_scores\n",
        "}).sort_values(\"confidence_percent\", ascending=False)\n",
        "\n",
        "explanation_df\n"
      ],
      "metadata": {
        "id": "W_9JO9pD9f_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Human interpretable text"
      ],
      "metadata": {
        "id": "E1h8fcpC9w7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a natural language explanation\n",
        "\n",
        "# Get predicted sleep score for this sample\n",
        "predicted_score = model.predict(x_single)[0]\n",
        "\n",
        "explanation_lines = []\n",
        "for idx, row in explanation_df.iterrows():\n",
        "    feature = row[\"feature\"]\n",
        "    direction = \"increased\" if row[\"shap_value\"] > 0 else \"decreased\"\n",
        "    percent = round(row[\"confidence_percent\"], 1)\n",
        "\n",
        "    explanation_lines.append(\n",
        "        f\"- {percent}% confidence: {feature} {direction} your sleep score\"\n",
        "    )\n",
        "\n",
        "final_explanation = (\n",
        "    f\"Predicted Sleep Score for this night: {predicted_score:.1f}/100\\n\\n\"\n",
        "    \"What affected your sleep the most:\\n\" +\n",
        "    \"\\n\".join(explanation_lines)\n",
        ")\n",
        "\n",
        "print(final_explanation)\n"
      ],
      "metadata": {
        "id": "o0tBPHqz9wWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Baselines & Bedtime proxy"
      ],
      "metadata": {
        "id": "nNsZgkMN_W_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute baseline HR and HRV for comparisons\n",
        "baseline_hr = df_scaled[\"hr_rolling\"].median()\n",
        "baseline_hrv = df_scaled[\"hrv_rolling\"].median()\n"
      ],
      "metadata": {
        "id": "rdXJttma_V_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Late bedtime proxy\n",
        "df_scaled[\"bedtime_proxy\"] = df_scaled.index.hour"
      ],
      "metadata": {
        "id": "Ngm5_mbR_bRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caffeine proxy (evening HR + motion)"
      ],
      "metadata": {
        "id": "MgHsi7Sz_q3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caffeine proxy (evening HR + motion)\n",
        "df_scaled[\"caffeine_proxy\"] = (\n",
        "    df_scaled[\"hr_rolling\"] * (df_scaled.index.hour >= 18)\n",
        "    +\n",
        "    df_scaled[\"motion_roll\"] * (df_scaled.index.hour >= 18)\n",
        ")\n"
      ],
      "metadata": {
        "id": "TzBbtfUy_lHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alcohol Proxy"
      ],
      "metadata": {
        "id": "3GIbCsZf_wp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alcohol proxy\n",
        "df_scaled[\"alcohol_proxy\"] = (\n",
        "    (df_scaled[\"temp_roll\"] - df_scaled[\"temp_roll\"].median()) +\n",
        "    (df_scaled[\"hr_rolling\"] - baseline_hr) -\n",
        "    (df_scaled[\"hrv_rolling\"] - baseline_hrv)\n",
        ")\n"
      ],
      "metadata": {
        "id": "XJVKAY_n_tR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stress Proxy"
      ],
      "metadata": {
        "id": "vGFuspiJ_1NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stress proxy\n",
        "df_scaled[\"stress_proxy\"] = (\n",
        "    (df_scaled[\"hr_rolling\"] / baseline_hr) -\n",
        "    (df_scaled[\"hrv_rolling\"] / baseline_hrv)\n",
        ")\n"
      ],
      "metadata": {
        "id": "dFEndgBC_2TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the Model to Include the 5 Lifestyle Proxies -- Defining new features set :)"
      ],
      "metadata": {
        "id": "ChMjQx-ZAEpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.columns\n"
      ],
      "metadata": {
        "id": "qvsSuVdJAels"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate activity proxy safely\n",
        "if \"steps\" in df_scaled.columns:\n",
        "    df_scaled[\"activity_proxy\"] = df_scaled[\"steps\"].fillna(0)\n",
        "else:\n",
        "    print(\"WARNING: 'steps' column missing!\")"
      ],
      "metadata": {
        "id": "hdgSLAsCAgkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"activity_proxy\" in df_scaled.columns\n"
      ],
      "metadata": {
        "id": "mgtWTzq6BH1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8A: Updated feature list (physiology + lifestyle)\n",
        "feature_cols = [\n",
        "    \"hr_rolling\",\n",
        "    \"hrv_rolling\",\n",
        "    \"motion_roll\",\n",
        "    \"rr_roll\",\n",
        "    \"temp_roll\",\n",
        "    \"bedtime_proxy\",\n",
        "    \"caffeine_proxy\",\n",
        "    \"alcohol_proxy\",\n",
        "    \"stress_proxy\",\n",
        "    \"activity_proxy\"\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X = df_scaled[feature_cols]\n",
        "y = df_scaled[\"sleep_score\"]\n",
        "\n",
        "# Clean missing values again (safety)\n",
        "X = X.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "y = y.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X.shape, y.shape\n"
      ],
      "metadata": {
        "id": "q0yRcAfT_8UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\n",
        "    \"hr_rolling\",\n",
        "    \"hrv_rolling\",\n",
        "    \"motion_roll\",\n",
        "    \"rr_roll\",\n",
        "    \"temp_roll\",\n",
        "    \"bedtime_proxy\",\n",
        "    \"caffeine_proxy\",\n",
        "    \"alcohol_proxy\",\n",
        "    \"stress_proxy\",\n",
        "    \"activity_proxy\"\n",
        "]\n",
        "\n",
        "X = df_scaled[feature_cols]\n",
        "y = df_scaled[\"sleep_score\"]\n",
        "\n",
        "X = X.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "y = y.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X.shape, y.shape\n"
      ],
      "metadata": {
        "id": "mmo_x5sCBPSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain model with new physiology + lifestyle features"
      ],
      "metadata": {
        "id": "BrwJyY26BVmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain model with new physiology + lifestyle features\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=7,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model retrained with lifestyle features!\")\n"
      ],
      "metadata": {
        "id": "sTCi1kImBVNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute SHAP Values for the New Model"
      ],
      "metadata": {
        "id": "bE_ec6omBgvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New SHAP explainer for lifestyle model\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"SHAP values updated for lifestyle model!\")\n"
      ],
      "metadata": {
        "id": "OKGfT9PbBhXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New SHAP summary plot"
      ],
      "metadata": {
        "id": "jCKQnksTVapl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "oh2iD7kmBylE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local SHAP explanations"
      ],
      "metadata": {
        "id": "O1PvCzy0B60y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Local SHAP explanation with confidence %\n",
        "\n",
        "# # Pick one sample from the test set to explain\n",
        "# # i = 19   # you can change this number to inspect different nights\n",
        "# x_single = X_test.iloc[[i]]\n",
        "\n",
        "# # SHAP values for this sample\n",
        "# shap_single = explainer.shap_values(x_single)[0]\n",
        "\n",
        "# # Absolute shap values → determine confidence\n",
        "# shap_abs = np.abs(shap_single)\n",
        "# confidence_scores = shap_abs / shap_abs.sum() * 100\n",
        "\n",
        "# # Build explanation dataframe\n",
        "# explanation_df = pd.DataFrame({\n",
        "#     \"feature\": X_test.columns,\n",
        "#     \"shap_value\": shap_single,\n",
        "#     \"confidence_percent\": confidence_scores\n",
        "# }).sort_values(\"confidence_percent\", ascending=False)\n",
        "\n",
        "# explanation_df\n"
      ],
      "metadata": {
        "id": "cTqjB64CB8MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Narrative Explanation"
      ],
      "metadata": {
        "id": "77uyIrHiDb5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a date you want to explain\n",
        "date_str = \"2025-11-06\"   # <-- change this to any date in your dataset\n",
        "\n",
        "target_date = pd.to_datetime(date_str).date()\n",
        "\n",
        "# Filter rows in X_test that belong to that calendar date\n",
        "mask = X_test.index.date == target_date\n",
        "X_test_for_date = X_test[mask]\n",
        "\n",
        "X_test_for_date.head()\n"
      ],
      "metadata": {
        "id": "Di-C_3dvV8zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick first row from that date to explain\n",
        "if len(X_test_for_date) == 0:\n",
        "    print(\"No data in X_test for that date. Try another date.\")\n",
        "else:\n",
        "    x_single = X_test_for_date.iloc[[0]]  # first row for that date\n",
        "    print(\"Using this timestamp for explanation:\", x_single.index[0])\n"
      ],
      "metadata": {
        "id": "rihqcMBXZnae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP values for the selected date's row\n",
        "\n",
        "shap_single = explainer.shap_values(x_single)[0]\n",
        "\n",
        "# absolute shap values → determine confidence\n",
        "shap_abs = np.abs(shap_single)\n",
        "confidence_scores = shap_abs / shap_abs.sum() * 100\n",
        "\n",
        "# Build the explanation dataframe\n",
        "explanation_df = pd.DataFrame({\n",
        "    \"feature\": X_test.columns,\n",
        "    \"shap_value\": shap_single,\n",
        "    \"confidence_percent\": confidence_scores\n",
        "}).sort_values(\"confidence_percent\", ascending=False)\n",
        "\n",
        "explanation_df\n"
      ],
      "metadata": {
        "id": "CCUorQMpZ8Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User-friendly narrative explanation for the selected date\n",
        "\n",
        "# Predicted sleep score for this date\n",
        "pred_score = model.predict(x_single)[0]\n",
        "\n",
        "# Map features to friendly names\n",
        "name_map = {\n",
        "    \"bedtime_proxy\": \"your bedtime\",\n",
        "    \"caffeine_proxy\": \"caffeine or stimulation before sleep\",\n",
        "    \"alcohol_proxy\": \"alcohol-like physiological effects\",\n",
        "    \"stress_proxy\": \"your stress level\",\n",
        "    \"activity_proxy\": \"your physical activity\",\n",
        "\n",
        "    \"hr_rolling\": \"your nighttime heart rate\",\n",
        "    \"hrv_rolling\": \"your HRV\",\n",
        "    \"motion_roll\": \"your restlessness\",\n",
        "    \"rr_roll\": \"your breathing rate\",\n",
        "    \"temp_roll\": \"your body temperature\"\n",
        "}\n",
        "\n",
        "# Build explanation lines\n",
        "user_lines = []\n",
        "for _, row in explanation_df.iterrows():\n",
        "    feature = row[\"feature\"]\n",
        "    percent = round(row[\"confidence_percent\"], 1)\n",
        "    direction = \"improved\" if row[\"shap_value\"] > 0 else \"reduced\"\n",
        "    readable = name_map.get(feature, feature.replace(\"_\", \" \"))\n",
        "\n",
        "    user_lines.append(f\"- {percent}% confidence → {readable} **{direction}** your sleep score\")\n",
        "\n",
        "# Build the final narrative\n",
        "narrative = f\"\"\"\n",
        "### Sleep Score Analysis for {date_str}\n",
        "\n",
        "Your predicted sleep score for this night is **{pred_score:.1f}/100**.\n",
        "\n",
        "Here’s what influenced your sleep the most:\n",
        "\n",
        "{chr(10).join(user_lines)}\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "These percentages show how strongly each factor contributed to your sleep score.\n",
        "Higher percentages mean greater influence — positive or negative.\n",
        "\n",
        "Lifestyle factors and physiological responses combine to form your nightly recovery:\n",
        "- Stress raises heart rate & lowers HRV\n",
        "- Caffeine elevates evening HR & delays sleep onset\n",
        "- Alcohol elevates temperature & suppresses HRV\n",
        "- Late bedtime shifts circadian alignment\n",
        "- Activity improves sleep drive\n",
        "- Physiological signals (HR, HRV, temperature, motion, breathing) show how your body responded\n",
        "\n",
        "\n",
        "### Personalized Suggestions\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Auto-suggestions based on negative contributors\n",
        "for _, row in explanation_df.iterrows():\n",
        "    feature = row[\"feature\"]\n",
        "    shap_val = row[\"shap_value\"]\n",
        "\n",
        "    if shap_val < 0:\n",
        "        if feature == \"stress_proxy\":\n",
        "            narrative += \"- Try calming down pre-bedtime — your body showed nighttime stress.\\n\"\n",
        "        elif feature == \"caffeine_proxy\":\n",
        "            narrative += \"- Reduce caffeine 6–8 hours before sleep — stimulant patterns were detected.\\n\"\n",
        "        elif feature == \"alcohol_proxy\":\n",
        "            narrative += \"- Alcohol-like physiological markers appeared; these often hurt HRV.\\n\"\n",
        "        elif feature == \"bedtime_proxy\":\n",
        "            narrative += \"- Your bedtime was later than your ideal rhythm.\\n\"\n",
        "        elif feature == \"activity_proxy\":\n",
        "            narrative += \"- Low daytime activity reduced your sleep drive.\\n\"\n",
        "        elif feature == \"hr_rolling\":\n",
        "            narrative += \"- Elevated heart rate reduced deep sleep potential.\\n\"\n",
        "        elif feature == \"hrv_rolling\":\n",
        "            narrative += \"- Lower HRV indicates your recovery was impaired.\\n\"\n",
        "        elif feature == \"motion_roll\":\n",
        "            narrative += \"- You experienced restlessness during sleep.\\n\"\n",
        "        elif feature == \"temp_roll\":\n",
        "            narrative += \"- Higher temperature indicates stress, alcohol, or late meals.\\n\"\n",
        "\n",
        "print(narrative)"
      ],
      "metadata": {
        "id": "Ps9IWa1gaOX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving outputs to a file in the sleep_xai_outputs folder"
      ],
      "metadata": {
        "id": "FIvpPcrPgcCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.to_csv(\n",
        "    \"/content/drive/MyDrive/XAI/sleep_xai_outputs/df_scaled.csv\"\n",
        ")\n",
        "\n",
        "print(\"Saved df_scaled.csv\")"
      ],
      "metadata": {
        "id": "j7coeJCigbnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(\n",
        "    model,\n",
        "    \"/content/drive/MyDrive/XAI/sleep_xai_outputs/model.pkl\"\n",
        ")\n",
        "\n",
        "print(\"Saved model.pkl\")"
      ],
      "metadata": {
        "id": "uejk1VGWgiHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(\n",
        "    explainer,\n",
        "    \"/content/drive/MyDrive/XAI/sleep_xai_outputs/explainer.pkl\"\n",
        ")\n",
        "\n",
        "print(\"Saved explainer.pkl\")"
      ],
      "metadata": {
        "id": "p60aHSDyglVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/XAI/sleep_xai_outputs/feature_cols.json\", \"w\") as f:\n",
        "    json.dump(feature_cols, f)\n",
        "\n",
        "print(\"Saved feature_cols.json\")"
      ],
      "metadata": {
        "id": "roPelSIGgnOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled.columns\n"
      ],
      "metadata": {
        "id": "q4NOgpET7F5C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}